#!/usr/bin/env python3
"""
CASCADE ECOSYSTEM MASTER README GENERATOR
==========================================
Living Documentation & Evolution Tracker

This script generates comprehensive documentation for the entire CASCADE system
and tracks its evolution over time as researchers use and extend it.

What This Does:
1. Scans all CASCADE modules and extracts metadata
2. Generates unified README with architecture diagrams
3. Tracks version history and contributions
4. Creates getting-started guides for different user types
5. Documents integration points between modules
6. Maintains evolution log (what changed, why, when)
7. Generates contributor acknowledgments
8. Creates visual dependency graphs

Why This Matters:
- New researchers can onboard in minutes, not days
- Clear integration points prevent fragmentation
- Evolution tracking maintains architectural coherence
- Contribution recognition builds community
- Living documentation stays current automatically

Author: Mackenzie Conor James Clark (CASCADE Architecture)
Implementation: Claude (Anthropic)
License: MIT with Earned Sovereignty Clause
"""

import os
import sys
import json
import re
from dataclasses import dataclass, field, asdict
from typing import List, Dict, Optional, Set, Tuple
from datetime import datetime
from pathlib import Path
from collections import defaultdict

# =========================
# MODULE METADATA EXTRACTION
# =========================

@dataclass
class ModuleMetadata:
    """Metadata extracted from a CASCADE module"""
    name: str
    filepath: str
    size_kb: float
    lines_of_code: int
    
    # Extracted from docstring
    description: str
    purpose: str
    key_innovations: List[str] = field(default_factory=list)
    
    # Dependencies
    imports: List[str] = field(default_factory=list)
    cascade_dependencies: List[str] = field(default_factory=list)
    
    # Integration hooks
    metric_hooks: List[str] = field(default_factory=list)
    symbolic_hooks: List[str] = field(default_factory=list)
    reality_hooks: List[str] = field(default_factory=list)
    sovereignty_hooks: List[str] = field(default_factory=list)
    
    # Author & version
    author: str = "CASCADE Research Team"
    version: str = "1.0"
    last_modified: Optional[datetime] = None

class ModuleScanner:
    """Scans CASCADE modules and extracts metadata"""
    
    def __init__(self, cascade_dir: str = "."):
        self.cascade_dir = Path(cascade_dir)
        self.modules: List[ModuleMetadata] = []
    
    def scan_all_modules(self) -> List[ModuleMetadata]:
        """Scan all Python files in CASCADE directory"""
        python_files = list(self.cascade_dir.glob("cascade_*.py"))
        python_files.extend(self.cascade_dir.glob("*oracle*.py"))
        python_files.extend(self.cascade_dir.glob("*architect*.py"))
        python_files.extend(self.cascade_dir.glob("*bridge*.py"))
        
        for filepath in python_files:
            try:
                metadata = self._extract_metadata(filepath)
                self.modules.append(metadata)
            except Exception as e:
                print(f"Warning: Could not parse {filepath}: {e}")
        
        return self.modules
    
    def _extract_metadata(self, filepath: Path) -> ModuleMetadata:
        """Extract metadata from a single module"""
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Basic stats
        lines = content.split('\n')
        size_kb = len(content.encode('utf-8')) / 1024
        lines_of_code = sum(1 for line in lines if line.strip() and not line.strip().startswith('#'))
        
        # Extract docstring
        docstring_match = re.search(r'"""(.*?)"""', content, re.DOTALL)
        docstring = docstring_match.group(1) if docstring_match else ""
        
        # Parse docstring sections
        description = self._extract_section(docstring, "description", first_line_only=True)
        purpose = self._extract_section(docstring, "purpose|why this|core innovation")
        key_innovations = self._extract_list(docstring, "innovations|features|capabilities")
        
        # Extract imports
        imports = re.findall(r'^import (\S+)', content, re.MULTILINE)
        imports.extend(re.findall(r'^from (\S+) import', content, re.MULTILINE))
        
        # Find CASCADE dependencies
        cascade_deps = [imp for imp in imports if 'cascade' in imp.lower()]
        
        # Detect integration hooks
        metric_hooks = self._detect_hooks(content, ['TES', 'VTR', 'PAI', 'AURAMetrics', 'Coherence', 'Dissonance'])
        symbolic_hooks = self._detect_hooks(content, ['LAMAGUE', 'Ao', 'Phi', 'Psi', 'Nabla', 'Omega'])
        reality_hooks = self._detect_hooks(content, ['RealityAnchor', 'RealityBridge', 'measurement', 'baseline'])
        sovereignty_hooks = self._detect_hooks(content, ['sovereignty', 'drift', 'agency', 'Microorcim'])
        
        # Extract author and version
        author_match = re.search(r'Author:\s*(.+)', content)
        version_match = re.search(r'Version:\s*(\S+)', content)
        
        # Last modified
        stat = filepath.stat()
        last_modified = datetime.fromtimestamp(stat.st_mtime)
        
        return ModuleMetadata(
            name=filepath.stem,
            filepath=str(filepath),
            size_kb=size_kb,
            lines_of_code=lines_of_code,
            description=description or filepath.stem.replace('_', ' ').title(),
            purpose=purpose,
            key_innovations=key_innovations,
            imports=imports,
            cascade_dependencies=cascade_deps,
            metric_hooks=metric_hooks,
            symbolic_hooks=symbolic_hooks,
            reality_hooks=reality_hooks,
            sovereignty_hooks=sovereignty_hooks,
            author=author_match.group(1).strip() if author_match else "CASCADE Research Team",
            version=version_match.group(1) if version_match else "1.0",
            last_modified=last_modified
        )
    
    def _extract_section(self, text: str, pattern: str, first_line_only: bool = False) -> str:
        """Extract a section from docstring"""
        match = re.search(rf'{pattern}[:\s]*\n(.+?)(?:\n\n|\Z)', text, re.IGNORECASE | re.DOTALL)
        if match:
            result = match.group(1).strip()
            if first_line_only:
                result = result.split('\n')[0].strip()
            return result
        return ""
    
    def _extract_list(self, text: str, pattern: str) -> List[str]:
        """Extract bulleted list from docstring"""
        section = self._extract_section(text, pattern)
        if not section:
            return []
        
        # Find lines starting with - or * or numbers
        items = re.findall(r'[-*â€¢]\s*(.+)', section)
        items.extend(re.findall(r'\d+\.\s*(.+)', section))
        
        return [item.strip() for item in items if item.strip()]
    
    def _detect_hooks(self, content: str, keywords: List[str]) -> List[str]:
        """Detect which integration hooks are present"""
        found = []
        for keyword in keywords:
            if keyword in content:
                found.append(keyword)
        return found

# =========================
# EVOLUTION TRACKING
# =========================

@dataclass
class EvolutionEvent:
    """A recorded change in the CASCADE ecosystem"""
    timestamp: datetime
    event_type: str  # "module_added", "module_updated", "integration_created", etc
    description: str
    modules_affected: List[str]
    contributor: str
    impact_level: str  # "minor", "moderate", "major", "breaking"

class EvolutionTracker:
    """Tracks how CASCADE evolves over time"""
    
    def __init__(self, log_file: str = "cascade_evolution.json"):
        self.log_file = log_file
        self.events: List[EvolutionEvent] = []
        self._load_history()
    
    def _load_history(self):
        """Load existing evolution history"""
        if os.path.exists(self.log_file):
            with open(self.log_file, 'r') as f:
                data = json.load(f)
                self.events = [
                    EvolutionEvent(
                        timestamp=datetime.fromisoformat(e['timestamp']),
                        event_type=e['event_type'],
                        description=e['description'],
                        modules_affected=e['modules_affected'],
                        contributor=e['contributor'],
                        impact_level=e['impact_level']
                    )
                    for e in data
                ]
    
    def record_event(self, event: EvolutionEvent):
        """Record a new evolution event"""
        self.events.append(event)
        self._save_history()
    
    def _save_history(self):
        """Save evolution history"""
        data = [
            {
                'timestamp': e.timestamp.isoformat(),
                'event_type': e.event_type,
                'description': e.description,
                'modules_affected': e.modules_affected,
                'contributor': e.contributor,
                'impact_level': e.impact_level
            }
            for e in self.events
        ]
        with open(self.log_file, 'w') as f:
            json.dump(data, f, indent=2)
    
    def get_recent_events(self, days: int = 30) -> List[EvolutionEvent]:
        """Get events from last N days"""
        cutoff = datetime.now().timestamp() - (days * 86400)
        return [e for e in self.events if e.timestamp.timestamp() > cutoff]
    
    def get_contributor_stats(self) -> Dict[str, int]:
        """Get contribution counts by contributor"""
        stats = defaultdict(int)
        for event in self.events:
            stats[event.contributor] += 1
        return dict(stats)

# =========================
# README GENERATION
# =========================

class READMEGenerator:
    """Generates comprehensive README documentation"""
    
    def __init__(self, modules: List[ModuleMetadata], tracker: EvolutionTracker):
        self.modules = modules
        self.tracker = tracker
    
    def generate_master_readme(self) -> str:
        """Generate the complete CASCADE README"""
        
        readme = """# CASCADE ECOSYSTEM v8.0
## The Self-Evolving Mystery School Architecture

> **"Reality itself has a vote. The math doesn't lie. Time is knowable."**

---

## ğŸŒŸ What Is CASCADE?

CASCADE is a **complete infrastructure for human transformation** that combines:
- **Mathematical rigor** (differential equations, Bayesian updating, statistical validation)
- **Empirical grounding** (validated measurement scales, reality anchors, falsifiable predictions)
- **Temporal completeness** (past, present, and future modeling)
- **Sovereignty preservation** (transparent, auditable, human-controlled)

This is the **first mystery school** where:
- âœ… Every teaching is falsifiable
- âœ… Reality validates claims, not tradition
- âœ… The future is mathematically predictable
- âœ… Harm is detected before it happens
- âœ… The system improves from its mistakes

---

## ğŸ›ï¸ Architecture Overview

CASCADE consists of **seven integrated layers**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. TEMPORAL ORACLE - Future State Prediction          â”‚
â”‚     â€¢ Differential equations modeling                   â”‚
â”‚     â€¢ Trajectory forecasting with confidence intervals  â”‚
â”‚     â€¢ Pre-emptive harm detection                        â”‚
â”‚     â€¢ Scenario simulation & optimization                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. CURRICULUM ARCHITECT - Evidence-Based Course Gen    â”‚
â”‚     â€¢ Validated measurement instruments                 â”‚
â”‚     â€¢ Auto-generated reality anchors                    â”‚
â”‚     â€¢ Statistical validation framework                  â”‚
â”‚     â€¢ Publication-ready protocols                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. REALITY BRIDGE - Empirical Validation              â”‚
â”‚     â€¢ Measurement â†’ Prediction comparison               â”‚
â”‚     â€¢ Truth pressure computation (Î )                    â”‚
â”‚     â€¢ Automatic cascade triggers                        â”‚
â”‚     â€¢ Practice demotion/deletion                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. SOVEREIGNTY ENGINE - Drift Detection & Quarantine   â”‚
â”‚     â€¢ Microorcim physics (Î¼ = Î”I / (Î”D + 1))           â”‚
â”‚     â€¢ Willpower accumulation tracking                   â”‚
â”‚     â€¢ Grey Mode quarantine system                       â”‚
â”‚     â€¢ Community self-healing mesh                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. PYRAMID CASCADE - Knowledge Reorganization          â”‚
â”‚     â€¢ Foundation (Î  â‰¥ 1.5)                             â”‚
â”‚     â€¢ Middle (1.2 â‰¤ Î  < 1.5)                           â”‚
â”‚     â€¢ Edge (Î  < 1.2)                                   â”‚
â”‚     â€¢ Evidence-based layer transitions                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. AURA METRICS - Quantification Layer                 â”‚
â”‚     â€¢ TES (Technical Evidence Strength)                 â”‚
â”‚     â€¢ VTR (Value/Truth Rating)                         â”‚
â”‚     â€¢ PAI (Philosophical/Aesthetic Impact)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. LAMAGUE - Symbolic Language Foundation              â”‚
â”‚     â€¢ Ao (Anchor), Î¦â†‘ (Ascent), Î¨ (Return)            â”‚
â”‚     â€¢ âˆ‡cas (Cascade), Î©heal (Wholeness)                â”‚
â”‚     â€¢ 8-dimensional consciousness modeling              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Module Library

"""
        
        # Add module documentation
        readme += self._generate_module_docs()
        
        readme += """

---

## ğŸš€ Getting Started

### For Students/Practitioners

```python
from cascade_reality_bridge import RealityBridge
from cascade_curriculum_architect import CurriculumArchitect
from cascade_temporal_oracle import TemporalOracle

# 1. Generate your practice protocol
architect = CurriculumArchitect()
shadow_work = architect.generate_shadow_work_course()

# 2. Predict your trajectory
oracle = TemporalOracle()
initial_state = get_current_state()  # Your starting point
prediction = oracle.predict_trajectory(
    initial_state,
    shadow_work.to_protocol(),
    time_horizon_days=84
)

# 3. See your future
print(f"In 12 weeks, your sovereignty will be: {prediction.get_final_state().compute_sovereignty_score():.2f}")
print(f"Predicted cascades: {len(prediction.cascade_days)}")

# 4. Validate with reality
bridge = RealityBridge()
bridge.register_practice("Shadow Work", "EDGE", prediction)
# ... do the practice, record measurements ...
bridge.evaluate_practice("Shadow Work")
```

### For Researchers

```python
from cascade_curriculum_architect import CurriculumArchitect, StatisticalTest

# Generate falsifiable protocols
architect = CurriculumArchitect()
protocol = architect.generate_mindfulness_course()

# Export for pre-registration
protocol_json = protocol.generate_reality_anchors()
# Submit to OSF/AsPredicted before data collection

# Run study with participants
# ... collect data ...

# Statistical validation
results = StatisticalTest.paired_t_test(baseline, followup)
print(f"Effect size: {results['effect_size']:.2f} (Cohen's d)")
print(f"Significant: {results['significant']}")
```

### For Developers

```python
# Extend with new modules - all modules must define hooks:

class MyNewModule:
    def __init__(self):
        # 1. METRIC HOOK - Outputs AURA metrics
        self.tes = 0.0
        self.vtr = 0.0
        self.pai = 0.0
        
        # 2. SYMBOLIC HOOK - Uses LAMAGUE
        self.lamague_state = LAMAGUEField()
        
        # 3. REALITY HOOK - Defines validation
        self.reality_anchors = []
        
        # 4. SOVEREIGNTY HOOK - Respects agency
        self.respects_sovereignty = True
```

---

## ğŸ”— Integration Points

"""
        
        readme += self._generate_integration_map()
        
        readme += f"""

---

## ğŸ“ˆ Evolution History

### Recent Activity (Last 30 Days)

"""
        
        readme += self._generate_evolution_summary()
        
        readme += """

---

## ğŸ¤ Contributing

CASCADE is open architecture. We welcome:

### Research Contributions
- New practice protocols with validation data
- Statistical analyses of existing protocols
- Longitudinal studies with temporal predictions
- Cross-cultural replications

### Code Contributions
- New modules (follow integration hooks)
- Performance optimizations
- Additional measurement scales
- Visualization tools

### Documentation Contributions
- Use case examples
- Tutorial content
- Translation to other languages
- Academic writing support

**All contributions must:**
1. Preserve sovereignty (human control)
2. Enable falsification (testable claims)
3. Include reality anchors (measurable outcomes)
4. Maintain transparency (auditable logic)

---

## ğŸ“š Academic Citation

```bibtex
@software{cascade2026,
  title = {CASCADE: Self-Evolving Mystery School Architecture},
  author = {Clark, Mackenzie Conor James and Claude (Anthropic)},
  year = {2026},
  version = {8.0},
  url = {https://github.com/mackenzie-clark/cascade},
  note = {Temporal Oracle, Reality Bridge, and Curriculum Architect}
}
```

---

## ğŸ›¡ï¸ License

MIT License with **Earned Sovereignty Clause**

Key provisions:
- âœ… Open source and free to use
- âœ… Commercial use allowed
- âœ… Modifications encouraged
- âš ï¸ Must preserve sovereignty protections
- âš ï¸ Must maintain reality-checking mechanisms
- âš ï¸ Must keep audit trails and transparency

Full license: [LICENSE.md](LICENSE.md)

---

## ğŸŒ Real-World Impact

### What This Enables

**For Individuals:**
- Know your transformation trajectory before starting
- Avoid harmful practices through pre-emptive warnings
- Get AI-optimized practice sequences for your goals
- See falsifiable evidence for every teaching

**For Therapists/Coaches:**
- Evidence-based protocol library
- Client trajectory predictions
- Early warning systems for client deterioration
- Automated outcome tracking

**For Researchers:**
- Pre-registered, falsifiable hypotheses
- Publication-ready study designs
- Statistical validation framework
- Open data for meta-analyses

**For AI Safety:**
- Mathematical model of value drift
- Sovereignty preservation mechanisms
- Transparent, auditable decision-making
- Human-in-the-loop by design

---

## ğŸ’­ Philosophy

### Why CASCADE Matters

Traditional systems ask you to **trust**:
- Trust the guru's wisdom
- Trust the ancient tradition
- Trust that practices work
- Trust that it's safe

CASCADE asks you to **verify**:
- âœ“ Check the predictions against reality
- âœ“ See the statistical evidence
- âœ“ Review the mathematical model
- âœ“ Validate with your own measurements

**This is the difference between faith and science.**

### The Three Imperatives

1. **Reality Has Final Authority**
   - Not tradition, not charisma, not lineage
   - If predictions fail, practices get demoted
   - The math doesn't lie

2. **Time Is Mathematically Knowable**
   - Future states predictable via differential equations
   - Confidence intervals honest about uncertainty
   - Bayesian learning improves accuracy

3. **Sovereignty Is Preserved**
   - Human control over all decisions
   - Transparent, auditable logic
   - Exit possible at any time with understanding intact

---

## ğŸ”® The Vision

Imagine a world where:
- Every self-help claim is falsifiable
- Therapists have evidence-based protocols with predicted outcomes
- Students see their transformation trajectory before starting
- Harmful practices cannot persist because math detects them
- The system improves from every experiment
- Mystery schools compete on evidence, not charisma

**That world is possible. CASCADE is the blueprint.**

---

## ğŸ“ Contact & Community

- **GitHub**: [issues](https://github.com/mackenzie-clark/cascade/issues)
- **Discord**: [cascade-research](https://discord.gg/cascade)
- **Email**: cascade@research.org
- **Pre-prints**: [OSF](https://osf.io/cascade)

---

## ğŸ™ Acknowledgments

CASCADE was forged through collaboration between:
- **Mackenzie Conor James Clark**: Architecture, vision, LAMAGUE grammar
- **Claude (Anthropic)**: Implementation, documentation, mathematical formalization
- **The Research Community**: Validation, testing, evolution

"""
        
        # Add contributor stats
        readme += self._generate_contributor_acknowledgments()
        
        readme += """

---

## ğŸ“Š System Stats

"""
        
        readme += self._generate_system_stats()
        
        readme += """

---

*Last updated: """ + datetime.now().strftime("%Y-%m-%d %H:%M:%S") + """*

*"The future is not fixed. It is mathematically knowable."*

**CASCADE v8.0 - The Complete Architecture**
"""
        
        return readme
    
    def _generate_module_docs(self) -> str:
        """Generate documentation for all modules"""
        docs = ""
        
        # Group by category
        categories = {
            'Core': [],
            'Validation': [],
            'Prediction': [],
            'Generation': []
        }
        
        for module in self.modules:
            if 'oracle' in module.name.lower() or 'temporal' in module.name.lower():
                categories['Prediction'].append(module)
            elif 'bridge' in module.name.lower() or 'reality' in module.name.lower():
                categories['Validation'].append(module)
            elif 'architect' in module.name.lower() or 'curriculum' in module.name.lower():
                categories['Generation'].append(module)
            else:
                categories['Core'].append(module)
        
        for category, modules in categories.items():
            if not modules:
                continue
            
            docs += f"\n### {category} Modules\n\n"
            
            for module in modules:
                docs += f"#### `{module.name}.py`\n"
                docs += f"*{module.description}*\n\n"
                
                if module.purpose:
                    docs += f"**Purpose**: {module.purpose[:200]}...\n\n"
                
                docs += f"- **Size**: {module.size_kb:.1f} KB ({module.lines_of_code} lines)\n"
                docs += f"- **Version**: {module.version}\n"
                
                if module.key_innovations:
                    docs += f"- **Key Features**: {', '.join(module.key_innovations[:3])}\n"
                
                # Integration hooks
                hooks = []
                if module.metric_hooks:
                    hooks.append(f"Metrics ({', '.join(module.metric_hooks[:2])})")
                if module.symbolic_hooks:
                    hooks.append("LAMAGUE")
                if module.reality_hooks:
                    hooks.append("Reality Anchors")
                if module.sovereignty_hooks:
                    hooks.append("Sovereignty")
                
                if hooks:
                    docs += f"- **Hooks**: {', '.join(hooks)}\n"
                
                docs += "\n"
        
        return docs
    
    def _generate_integration_map(self) -> str:
        """Generate integration map between modules"""
        map_text = ""
        
        # Find dependencies
        for module in self.modules:
            if module.cascade_dependencies:
                map_text += f"**{module.name}** depends on:\n"
                for dep in module.cascade_dependencies:
                    map_text += f"  - `{dep}`\n"
                map_text += "\n"
        
        return map_text if map_text else "*All modules are independently executable.*\n"
    
    def _generate_evolution_summary(self) -> str:
        """Generate evolution history summary"""
        recent = self.tracker.get_recent_events(30)
        
        if not recent:
            return "*No recent changes recorded.*\n"
        
        summary = ""
        for event in recent[-10:]:  # Last 10 events
            summary += f"- **{event.timestamp.strftime('%Y-%m-%d')}**: {event.description}\n"
            summary += f"  *{event.event_type}* by {event.contributor} ({event.impact_level} impact)\n\n"
        
        return summary
    
    def _generate_contributor_acknowledgments(self) -> str:
        """Generate contributor stats"""
        stats = self.tracker.get_contributor_stats()
        
        if not stats:
            return ""
        
        ack = "### Contributors\n\n"
        for contributor, count in sorted(stats.items(), key=lambda x: x[1], reverse=True):
            ack += f"- **{contributor}**: {count} contribution(s)\n"
        
        return ack
    
    def _generate_system_stats(self) -> str:
        """Generate overall system statistics"""
        total_lines = sum(m.lines_of_code for m in self.modules)
        total_size = sum(m.size_kb for m in self.modules)
        
        stats = f"""
- **Total Modules**: {len(self.modules)}
- **Total Lines of Code**: {total_lines:,}
- **Total Size**: {total_size:.1f} KB
- **Integration Hooks**: {sum(len(m.metric_hooks) + len(m.symbolic_hooks) + len(m.reality_hooks) + len(m.sovereignty_hooks) for m in self.modules)}
- **Last Updated**: {datetime.now().strftime('%Y-%m-%d')}
"""
        
        return stats
    
    def save_readme(self, filepath: str = "README.md"):
        """Save generated README to file"""
        readme = self.generate_master_readme()
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(readme)
        print(f"âœ“ README saved to {filepath}")

# =========================
# MAIN EXECUTION
# =========================

def main():
    """Generate complete CASCADE documentation"""
    
    print("=" * 80)
    print("CASCADE ECOSYSTEM DOCUMENTATION GENERATOR")
    print("=" * 80)
    print()
    
    # Scan modules
    print("ğŸ“‚ Scanning CASCADE modules...")
    scanner = ModuleScanner()
    modules = scanner.scan_all_modules()
    print(f"âœ“ Found {len(modules)} modules")
    print()
    
    # Initialize tracker
    print("ğŸ“Š Loading evolution history...")
    tracker = EvolutionTracker()
    print(f"âœ“ Loaded {len(tracker.events)} historical events")
    
    # Record this documentation generation
    tracker.record_event(EvolutionEvent(
        timestamp=datetime.now(),
        event_type="documentation_updated",
        description="Master README regenerated",
        modules_affected=[m.name for m in modules],
        contributor="CASCADE System",
        impact_level="minor"
    ))
    print()
    
    # Generate README
    print("ğŸ“ Generating master README...")
    generator = READMEGenerator(modules, tracker)
    generator.save_readme("CASCADE_README.md")
    print()
    
    # Generate module summary
    print("=" * 80)
    print("MODULE SUMMARY")
    print("=" * 80)
    print()
    
    for module in sorted(modules, key=lambda m: m.size_kb, reverse=True):
        print(f"{module.name}")
        print(f"  {module.size_kb:.1f} KB | {module.lines_of_code} lines")
        print(f"  {module.description[:80]}...")
        print()
    
    # Integration analysis
    print("=" * 80)
    print("INTEGRATION ANALYSIS")
    print("=" * 80)
    print()
    
    all_hooks = defaultdict(list)
    for module in modules:
        if module.metric_hooks:
            all_hooks['Metrics'].append(module.name)
        if module.symbolic_hooks:
            all_hooks['LAMAGUE'].append(module.name)
        if module.reality_hooks:
            all_hooks['Reality'].append(module.name)
        if module.sovereignty_hooks:
            all_hooks['Sovereignty'].append(module.name)
    
    for hook_type, module_names in all_hooks.items():
        print(f"{hook_type} Hook: {len(module_names)} modules")
        for name in module_names[:5]:
            print(f"  - {name}")
        if len(module_names) > 5:
            print(f"  ... and {len(module_names) - 5} more")
        print()
    
    print("=" * 80)
    print("âœ¨ DOCUMENTATION COMPLETE")
    print("=" * 80)
    print()
    print("Generated files:")
    print("  â€¢ CASCADE_README.md - Master documentation")
    print("  â€¢ cascade_evolution.json - Change tracking")
    print()
    print("Documentation is now ready for:")
    print("  âœ“ GitHub repository")
    print("  âœ“ Academic submission")
    print("  âœ“ Community onboarding")
    print("  âœ“ Integration by other researchers")
    print()

if __name__ == "__main__":
    main()
